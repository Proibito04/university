{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a0e63ce",
   "metadata": {},
   "source": [
    "# Lab #1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df7a712",
   "metadata": {},
   "source": [
    "The purpose of this laboratory is to get you acquainted with Python. \n",
    "More specifically, you will learn how to:\n",
    "- read different types of datasets (CSV and JSON). \n",
    "- extract some useful information (mean and standard deviation) from the datasets while only using basic python.\n",
    "- create a simple rule-based classifier that is already capable to perform some classification.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bdb4439",
   "metadata": {},
   "source": [
    "## Preliminaries\n",
    "### Python availability\n",
    "Make sure that Python 3 is installed on your device with the commands `python --version`. The version should be in the form `3.x.x.`"
   ]
  },
  {
   "cell_type": "code",
   "id": "2bd291ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T07:45:27.511439Z",
     "start_time": "2024-10-04T07:45:27.401006Z"
    }
   },
   "source": [
    "! python3 --version"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.12.3\r\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "05e6a809",
   "metadata": {},
   "source": [
    "### Dataset Download\n",
    "For this lab, three different datasets will be used. Here, you will learnmore about them and how to retrieve\n",
    "them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43b2a4d",
   "metadata": {},
   "source": [
    "#### Iris\n",
    "Iris is a particularly famous *toy dataset* (i.e. a dataset with a small number of rows and columns, mostly\n",
    "used for initial small-scale tests and proofs of concept). \n",
    "This specific dataset contains information about the **Iris**, a genus that includes 260-300 species of plants. \n",
    "The Iris dataset contains measurements for 150 Iris flowers, each belonging to one of three species (50 flowers each): \n",
    "\n",
    "Iris Virginica             |  Iris Versicolor          |   Iris Setosa  |\n",
    ":-------------------------:|:-------------------------:|:---------------|\n",
    ":<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/f/f8/Iris_virginica_2.jpg/1200px-Iris_virginica_2.jpg\" alt=\"Iris Virginica\" width=\"200\" /> | <img src=\"https://www.waternursery.it/document/img_prodotti/616/1646318149.jpeg\" alt=\"Iris Versicolor\" width=\"200\" /> |<img src=\"https://d2j6dbq0eux0bg.cloudfront.net/images/28296135/2323483832.jpg\" alt=\"Iris Setosa\" width=\"200\" />|\n",
    "\n",
    "Each of the 150 flowers contained in the Iris dataset is represented by 5 values:\n",
    "- sepal length, in cm\n",
    "- sepal width, in cm\n",
    "- petal length, in cm\n",
    "- petal width, in cm\n",
    "- Iris species, one of: Iris-setosa, Iris-versicolor, Iris-virginica (the label)\n",
    "\n",
    "Each row of the dataset represents a distinct flower (as such, the dataset will have 150 rows). Each\n",
    "row then contains 5 values (4 measurements and a species label).\n",
    "The dataset is described in more detail on the [UCI Machine Learning Repository website](https://archive.ics.uci.edu/dataset/53/iris). The dataset\n",
    "can either be downloaded directly from there (iris.data file), or from a terminal, using the `wget` tool. The\n",
    "following command downloads the dataset from the original URL and stores it in a file named iris.csv.\n",
    "\n",
    "`wget \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\" -O iris.csv`\n",
    "\n",
    "The dataset is available as a Comma-Separated Values (CSV) file. These files are typically used to\n",
    "represent tabular data. \n",
    "- Each row is represented on one of the lines. \n",
    "- Each of the rows contains a fixed number of columns. \n",
    "- Each of the columns (in each row) is separated by a comma (,).\n",
    "\n",
    "To read CSV files, Python offers a module called `csv` (here the offical [doc](https://docs.python.org/3/library/csv.html)). This module allows using `csv.reader()`, which\n",
    "reads a file row by row. For each row, it returns a list of columns that can be processed as needed. \n",
    "\n",
    "\n",
    "Let's download the dataset and print the first three rows.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "94138fd0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T07:45:29.305421Z",
     "start_time": "2024-10-04T07:45:27.521085Z"
    }
   },
   "source": [
    "! wget \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\" -O iris.csv\n",
    "\n",
    "print(\"Reading first lines of IRIS dataset\")\n",
    "import csv \n",
    "with open(\"iris.csv\") as f:\n",
    "    for i, cols in enumerate(csv.reader(f)):\n",
    "        print(cols)\n",
    "        if i >= 4:\n",
    "            break"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-10-04 09:45:27--  https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\r\n",
      "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\r\n",
      "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: unspecified\r\n",
      "Saving to: ‘iris.csv’\r\n",
      "\r\n",
      "iris.csv                [ <=>                ]   4.44K  --.-KB/s    in 0s      \r\n",
      "\r\n",
      "2024-10-04 09:45:29 (95.1 MB/s) - ‘iris.csv’ saved [4551]\r\n",
      "\r\n",
      "Reading first lines of IRIS dataset\n",
      "['5.1', '3.5', '1.4', '0.2', 'Iris-setosa']\n",
      "['4.9', '3.0', '1.4', '0.2', 'Iris-setosa']\n",
      "['4.7', '3.2', '1.3', '0.2', 'Iris-setosa']\n",
      "['4.6', '3.1', '1.5', '0.2', 'Iris-setosa']\n",
      "['5.0', '3.6', '1.4', '0.2', 'Iris-setosa']\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "3ecb2df8",
   "metadata": {},
   "source": [
    "Note by default, csv.reader converts all fields read into strings (str). \n",
    "If you want to treat them as number, remember to cast them correctly!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5725ff17",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### MNIST\n",
    "The MNIST dataset is another particularly famous dataset. It contains several thousands of hand-written\n",
    "digits (0 to 9). \n",
    "- Each hand-written digit is contained in an image represented as $28 x 28$ 8-bit grayscale image. \n",
    "- This means that each digit has $784$ ($28^2$) pixels\n",
    "- Each pixel has a value that ranges from 0 (black) to 255 (white).\n",
    "\n",
    "<img src=\"https://machinelearningmastery.com/wp-content/uploads/2019/02/Plot-of-a-Subset-of-Images-from-the-MNIST-Dataset.png\" alt=\"MNIST images\" width=\"500\" />\n",
    "\n",
    "The dataset can be downloaded from the following link:\n",
    "\n",
    "[https://raw.githubusercontent.com/dbdmg/data-science-lab/master/datasets/mnist_test.csv](https://raw.githubusercontent.com/dbdmg/data-science-lab/master/datasets/mnist_test.csv)\n",
    "\n",
    "In this case, MNIST is represented as a CSV file. Similarly to the Iris dataset, each row of the MNIST\n",
    "datasets represents the pixels of the image representing a digit. For the sake of simplicity, this dataset contains only a small fraction (10; 000\n",
    "digits out of 70; 000) of the real MNIST dataset. \n",
    "\n",
    "For each digit, 785 values are available: \n",
    "- the first one is the numerical value depicted in the image (e.g. for Figure 2 it would be 5). \n",
    "- the following 784 columns represent the grayscale image in row-major order (for more information about row- and column-major order of matrices, see [Wikipedia](https://en.wikipedia.org/wiki/Row-_and_column-major_order)).\n",
    "\n",
    "The MNIST dataset in CSV format can be read with the same approach used for Iris, keeping in mind\n",
    "that, in this case, the digit label (i.e. the first column) is an integer from 0 to 9, while the following 784\n",
    "values are integers between 0 and 255."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7532fe60",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "Note that exercises marked with a (*) are optional, you should focus on completing the other ones first.\n",
    "### Iris analysis\n",
    "1. Load the previously downloaded Iris dataset as a list of lists (each of the 150 lists should have 5 elements). You can make use of the csv module presented"
   ]
  },
  {
   "cell_type": "code",
   "id": "9379bd5669ca8db9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T07:45:29.320555Z",
     "start_time": "2024-10-04T07:45:29.317709Z"
    }
   },
   "source": [
    "import csv\n",
    "\n",
    "dataset = []\n",
    "\n",
    "with open(\"iris.csv\") as f:\n",
    "    for i, cols in enumerate(csv.reader(f)):\n",
    "        dataset.append([cols[0], cols[1], cols[2], cols[3], cols[4]])\n",
    "        if i >= 4:\n",
    "            break\n",
    "\n",
    "print(dataset)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['5.1', '3.5', '1.4', '0.2', 'Iris-setosa'], ['4.9', '3.0', '1.4', '0.2', 'Iris-setosa'], ['4.7', '3.2', '1.3', '0.2', 'Iris-setosa'], ['4.6', '3.1', '1.5', '0.2', 'Iris-setosa'], ['5.0', '3.6', '1.4', '0.2', 'Iris-setosa']]\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "1bbcdf393c1b88a7",
   "metadata": {},
   "source": [
    "2. Compute and print the mean and the standard deviation for each of the 4 measurement columns (i.e. sepal length and width, petal length and width). Remember that, for a given list of n values $x = (x_1, x_2, ..., x_n)$, the mean $\\mu$ and the standard deviation $\\sigma$ are defined respectively as:\n",
    "$$\\mu = {1 \\over n} \\sum_i^n x_i $$\n",
    "\n",
    "$$ \\sigma = \\sqrt{ {1 \\over n} \\sum_i^n (x_i - \\mu)^2} $$"
   ]
  },
  {
   "cell_type": "code",
   "id": "a8c4f766f46b3e23",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T07:45:29.373666Z",
     "start_time": "2024-10-04T07:45:29.368161Z"
    }
   },
   "source": [
    "import csv\n",
    "import math\n",
    "\n",
    "\n",
    "dataset = []\n",
    "means = [0,0,0,0]\n",
    "std = [0,0,0,0]\n",
    "with open(\"iris.csv\") as f:\n",
    "    for i, cols in enumerate(csv.reader(f)):\n",
    "        data = [0,0,0,0]\n",
    "        k = 0\n",
    "        for c in cols[:-1]:\n",
    "            el = float(c)\n",
    "            means[k] += el\n",
    "            data[k] = el\n",
    "            k += 1\n",
    "        dataset.append(data)\n",
    "\n",
    "for idx, i in enumerate(means):\n",
    "    means[idx] = i / len(dataset)\n",
    "\n",
    "for i in dataset:\n",
    "    k = 0\n",
    "    for idx, el in enumerate(i):\n",
    "        curr = pow(el - means[idx], 2)\n",
    "        std[idx] += curr\n",
    "\n",
    "for idx, i in enumerate(std):\n",
    "    std[idx] = math.sqrt(i / len(dataset))\n",
    "print(len(dataset))\n",
    "\n",
    "print(means)\n",
    "print(std)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151\n",
      "[5.804635761589405, 3.033774834437087, 3.7337748344370887, 1.1907284768211928]\n",
      "[0.949334918698444, 0.49686266270656754, 1.7790125774218053, 0.7642986650871321]\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "1015b464055be7bd",
   "metadata": {},
   "source": [
    "\n",
    "3. Compute and print the mean and the standard deviation for each of the 4 measurement columns, separately for each of the three Iris species (versicolor, virginica and setosa)."
   ]
  },
  {
   "cell_type": "code",
   "id": "8372b07413d00161",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T07:45:29.432553Z",
     "start_time": "2024-10-04T07:45:29.427458Z"
    }
   },
   "source": [
    "import csv\n",
    "import math\n",
    "\n",
    "dataset = []\n",
    "means = [0,0,0,0]\n",
    "std = [0,0,0,0]\n",
    "with open(\"iris.csv\") as f:\n",
    "    for i, cols in enumerate(csv.reader(f)):\n",
    "        data = [0,0,0,0]\n",
    "        k = 0\n",
    "        if len(cols) != 5: continue\n",
    "        for c in cols[:-1]:\n",
    "            el = float(c)\n",
    "            means[k] += el\n",
    "            data[k] = el\n",
    "            k += 1\n",
    "        dataset.append(data)\n",
    "\n",
    "\n",
    "\n",
    "for idx, i in enumerate(means):\n",
    "    means[idx] = i / len(dataset)\n",
    "\n",
    "for i in dataset:\n",
    "    k = 0\n",
    "    for idx, el in enumerate(i):\n",
    "        curr = pow(el - means[idx], 2)\n",
    "        std[idx] += curr\n",
    "\n",
    "for idx, i in enumerate(std):\n",
    "    std[idx] = math.sqrt(i / len(dataset))\n",
    "print(len(dataset))\n",
    "\n",
    "print(means)\n",
    "print(std)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n",
      "[5.843333333333335, 3.0540000000000007, 3.7586666666666693, 1.1986666666666672]\n",
      "[0.8253012917851409, 0.4321465800705435, 1.7585291834055201, 0.760612618588172]\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "id": "a8a57e3baea8eae1",
   "metadata": {},
   "source": [
    "\n",
    "4. Based on the results of exercises 2 and 3, which of the 4 measurements would you considering as being the most characterizing one for the three species? (In other words, which measurement would you consider “best”, if you were to guess the Iris species based only on those four values?)"
   ]
  },
  {
   "cell_type": "code",
   "id": "aff6224527faf6ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T07:45:29.545223Z",
     "start_time": "2024-10-04T07:45:29.538600Z"
    }
   },
   "source": [
    "import csv\n",
    "import math\n",
    "from collections import defaultdict\n",
    "from pprint import pprint\n",
    "\n",
    "dataset = []\n",
    "\n",
    "means_map = {}\n",
    "# name => [sepal_length, sepal_width, petal_length, petal_width, count]\n",
    "\n",
    "with open(\"iris.csv\") as f:\n",
    "  for i, cols in enumerate(csv.reader(f)):\n",
    "    if len(cols) != 5: continue \n",
    "\n",
    "    data = [0,0,0,0, \"\"]\n",
    "    k = 0\n",
    "    if cols[4] not in means_map:\n",
    "      means_map[cols[4]] = [0,0,0,0,0]\n",
    "    \n",
    "    for idx, c in enumerate(cols):\n",
    "      if idx == 4:\n",
    "        data[4] = c\n",
    "        break\n",
    "      el = float(c)\n",
    "      means_map[cols[4]][idx] += el\n",
    "      data[k] = el\n",
    "\n",
    "      k += 1\n",
    "    means_map[cols[4]][4] += 1\n",
    "    dataset.append(data)\n",
    "\n",
    "# calculate means\n",
    "for key, value in means_map.items():\n",
    "  for idx,val in enumerate(value[:-1]):\n",
    "    means_map[key][idx] = val / value[-1]\n",
    "\n",
    "print(\"Means:\")\n",
    "pprint(means_map)\n",
    "\n",
    "std_maps = defaultdict(lambda: [0, 0, 0, 0, 0])\n",
    "\n",
    "\n",
    "for idx, row in enumerate(dataset):\n",
    "  if row[4] not in std_maps:\n",
    "    std_maps[row[4]] = [0,0,0,0]\n",
    "\n",
    "  for idx, el in enumerate(row[:-1]):\n",
    "    std_maps[row[4]][idx] += (el - means_map[row[4]][idx]) ** 2\n",
    "\n",
    "for key, value in std_maps.items():\n",
    "  for idx, col in enumerate(value):\n",
    "    std_maps[key][idx] = math.sqrt(std_maps[key][idx] / means_map[key][4])\n",
    "\n",
    "print(\"\")\n",
    "print(\"Standard deviation:\")\n",
    "pprint(dict(std_maps))\n",
    "\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Means:\n",
      "{'Iris-setosa': [5.005999999999999,\n",
      "                 3.4180000000000006,\n",
      "                 1.464,\n",
      "                 0.2439999999999999,\n",
      "                 50],\n",
      " 'Iris-versicolor': [5.936, 2.7700000000000005, 4.26, 1.3259999999999998, 50],\n",
      " 'Iris-virginica': [6.587999999999998, 2.9739999999999998, 5.552, 2.026, 50]}\n",
      "\n",
      "Standard deviation:\n",
      "{'Iris-setosa': [0.348946987377739,\n",
      "                 0.37719490982779713,\n",
      "                 0.17176728442867115,\n",
      "                 0.10613199329137278],\n",
      " 'Iris-versicolor': [0.5109833656783752,\n",
      "                     0.31064449134018135,\n",
      "                     0.4651881339845204,\n",
      "                     0.19576516544063702],\n",
      " 'Iris-virginica': [0.6294886813914925,\n",
      "                    0.319255383666431,\n",
      "                    0.5463478745268441,\n",
      "                    0.2718896835115301]}\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "id": "be6f631cb71fb4c9",
   "metadata": {},
   "source": [
    "\n",
    "5. Based on the considerations of Exercise 3, assign the flowers with the following measurements to what you consider would be the most likely species.\n",
    "````\n",
    "5.2, 3.1, 4.0, 1.2 -> 'Iris-versicolor'\n",
    "4.9, 2.5, 5.6, 2.0 -> 'Iris-virginica'\n",
    "5.4, 3.2, 1.9, 0.4 -> 'Iris-setosa'\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b9f6d1c6a4304c",
   "metadata": {},
   "source": [
    "\n",
    "6. (*) Create a Rule-based classifier similar to the one seen in class. This classifier, again, will receive some rule and will classify each sample into one of the three species."
   ]
  },
  {
   "cell_type": "code",
   "id": "d9e8b272c7ff4e78",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T07:45:29.591823Z",
     "start_time": "2024-10-04T07:45:29.589679Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4acda37f8fa9e27d",
   "metadata": {},
   "source": [
    "7. (*) Compute prediction for all the elements in the dataset and store them in a list. Then, compute the accuracy of the classifier that you create. Remember that the accuracy metric is:\n",
    "\n",
    "$$ {\\text{number of correct predictions (TP + TN)} \\over \\text{total number of predictions (TP+TN+FP+FN)}} $$\n",
    "\n",
    "Where one can check whether the prediction is correct by looking at the label of the sample ($5^{th}$ column)"
   ]
  },
  {
   "cell_type": "code",
   "id": "120f43768967753c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T07:45:29.636089Z",
     "start_time": "2024-10-04T07:45:29.634346Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "46442757",
   "metadata": {},
   "source": [
    "### MNIST Analysis\n",
    "\n",
    "1. Load the previously downloaded MNIST dataset. You can make use of the csv module already presented."
   ]
  },
  {
   "cell_type": "code",
   "id": "70e93e04",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T07:45:29.709647Z",
     "start_time": "2024-10-04T07:45:29.693594Z"
    }
   },
   "source": [
    "import csv\n",
    "\n",
    "def print_char(char):\n",
    "  if char < 64:\n",
    "    print(\" \", end=\"\")\n",
    "  elif 64 <= char and char < 128:\n",
    "    print(\".\", end=\"\")\n",
    "  elif 128 <= char and char < 192:\n",
    "    print(\"*\", end=\"\")\n",
    "  elif 192 <= char and char < 256:\n",
    "    print(\"#\", end=\"\")\n",
    "\n",
    "print(\"start\")\n",
    "with open(\"MNIST\") as f:\n",
    "  for i, row in enumerate(csv.reader(f)):\n",
    "    for idx, el in enumerate(row):\n",
    "      print_char(int(el))\n",
    "      if idx % 28 == 0:\n",
    "        print()\n",
    "\n",
    "    if i == 4:\n",
    "      break"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      " \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "      .***                  \n",
      "      ##############*       \n",
      "      ....*##########*      \n",
      "            . ...  ##.      \n",
      "                  .##       \n",
      "                  ##.       \n",
      "                 *##        \n",
      "                 ##         \n",
      "                *#*         \n",
      "                ##          \n",
      "               .#*          \n",
      "              .##           \n",
      "              ##*           \n",
      "             ###            \n",
      "             ##.            \n",
      "            ##.             \n",
      "           *##              \n",
      "           ###              \n",
      "          .###              \n",
      "          .##               \n",
      "                            \n",
      " \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "          ..*##*.           \n",
      "         *#######           \n",
      "        *####**##.          \n",
      "        ###    ##*          \n",
      "       .##    .##.          \n",
      "              ###.          \n",
      "             .###           \n",
      "            .###            \n",
      "            *##*            \n",
      "           *##*             \n",
      "           ###              \n",
      "          ###*              \n",
      "         .##*               \n",
      "         ###*               \n",
      "        *##*                \n",
      "        ###                 \n",
      "        ###           ****  \n",
      "        ########***#######. \n",
      "        *##############*..  \n",
      "         ....*###*..        \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      " \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                 #.         \n",
      "                .#.         \n",
      "                *#          \n",
      "                #*          \n",
      "               .#           \n",
      "               ##           \n",
      "               ##           \n",
      "              .##           \n",
      "              *#.           \n",
      "              ##            \n",
      "             .#*            \n",
      "             *#.            \n",
      "             ##             \n",
      "            .#*             \n",
      "            *#*             \n",
      "            ##.             \n",
      "            ##.             \n",
      "           *##              \n",
      "           ##.              \n",
      "           #*               \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      " \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "             *##            \n",
      "             ###.           \n",
      "            ####.           \n",
      "          .*####*.          \n",
      "          #########         \n",
      "         *##########        \n",
      "         #####*. *##.       \n",
      "        #####*    ###.      \n",
      "        ###*      .###      \n",
      "        ###        ###      \n",
      "        ##         ###*     \n",
      "       *##        .###      \n",
      "       ###        ####      \n",
      "       ###      *####       \n",
      "       ###     *####*       \n",
      "       ###..########        \n",
      "       .###########*        \n",
      "        #########*          \n",
      "         *######.           \n",
      "          .*#*..            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      " \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "           #       .        \n",
      "          .#       **       \n",
      "          ##       .#       \n",
      "         .#*       .#       \n",
      "         ##        ##       \n",
      "        *#         ##       \n",
      "       .##        *#*       \n",
      "       *#.        ##.       \n",
      "       ##        *##        \n",
      "       #*        *#*        \n",
      "       ##        ##.        \n",
      "       *##....**###.        \n",
      "        *##########         \n",
      "          ....  *##         \n",
      "                .##         \n",
      "                *##         \n",
      "                .##         \n",
      "                *##         \n",
      "                ##.         \n",
      "                *.          \n",
      "                            \n",
      "                            \n",
      "                            \n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "725ddad1ee7b1c1b",
   "metadata": {},
   "source": [
    "2. Create a function that, given a position $1 < k < 10,000$, prints the $k^{th}$ sample of the dataset (i.e. the $k^{th}$ row of the csv file) as a grid of $28x28$ characters. More specifically, you should map each range of pixel values to the following characters:\n",
    "    - [0; 64) &rarr; \" \"\n",
    "    - [64; 128) &rarr; \".\"\n",
    "    - [128; 192) &rarr; \"*\"\n",
    "    - [192; 256) &rarr; \"#\"\n",
    "So, for example, you should map the sequence `0, 72, 192, 138, 250` to the string `.#*#`.\n",
    "*Note*: Remember to start a new line every time you read 28 characters\n",
    "\n",
    "Example of output: \n",
    "```\n",
    "         .#      **\n",
    "        .##..*#####\n",
    "       #########*.\n",
    "      #####***.\n",
    "     ##*\n",
    "    *##\n",
    "    ##\n",
    "   .##\n",
    "    ###*\n",
    "    .#####.\n",
    "        *###*\n",
    "           *###*\n",
    "              ###\n",
    "              .##\n",
    "              ###\n",
    "            .###\n",
    "      .    *###.\n",
    "     .#  .*###*\n",
    "     .######.\n",
    "      *##*.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "77672741a499b98d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T07:45:29.755350Z",
     "start_time": "2024-10-04T07:45:29.753730Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "abc23e028f2b3979",
   "metadata": {},
   "source": [
    "3. Compute the Euclidean distance between each pair of the 784-dimensional vectors of the digits at\n",
    "the following positions: $26^{th}$, $30^{th}$, $32^{nd}$, $35^{th}$.\n",
    "\n",
    "*Note*: Remember that Python arrays are indexed from 0, so the $k^{th}$ value will be at position $k-1$"
   ]
  },
  {
   "cell_type": "code",
   "id": "bb3ddc8c6c9571d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T07:45:29.802382Z",
     "start_time": "2024-10-04T07:45:29.800411Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c2a988794dbd7294",
   "metadata": {},
   "source": [
    "4. Based on the distances computed in the previous step and knowing that the digits listed in Exercise 3 are (not necessarily in this order) $0, 1, 1, 7$ can you assign the correct label to each of the digits of Exercise 3?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6c2fbf5d334780",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c19bf11e0d25a0af",
   "metadata": {},
   "source": [
    "5. There are 1,135 images representing 1’s and 980 images representing 0’s in the dataset. For all 0’s and 1’s separately, count the number of times each of the 784 pixels is black (use 128 as the threshold value). You can do this by building a list `Z` and a list `O`, each containing 784 elements, containing respectively the counts for the 0’s and the 1’s. `Z[i]` and `O[i]` contain the number of times the $i^{th}$ pixel was black for either class. For each value i, compute `abs(Z[i] - O[i])`. The $i$ with the highest value represents the pixel that best separates the digits “0” and “1” (i.e. the pixel that is most often black for one class and white for the other). Where is this pixel located within the grid? Why is it?"
   ]
  },
  {
   "cell_type": "code",
   "id": "d0b1ca74cb547174",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T07:45:29.849307Z",
     "start_time": "2024-10-04T07:45:29.847260Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b36c9eda73610bca",
   "metadata": {},
   "source": [
    "6. (*) Extract a subset of the MNIST dataset composed of only 0 and 1 digits. Create a Rule-based classifier that take as input the rule that you discovered in ex. 5. As previously then, compute the prediction of such a classifier on all the samples in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "id": "e56ccd823714b00f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T07:45:29.894417Z",
     "start_time": "2024-10-04T07:45:29.892771Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
